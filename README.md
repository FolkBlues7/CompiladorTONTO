# Analisador LÃ©xico para a Linguagem TONTO

## ğŸ§© Fase 1 â€” AnÃ¡lise LÃ©xica (Lexer)

Projeto da disciplina de Compiladores para a criaÃ§Ã£o de um analisador lÃ©xico em Python para a "Textual Ontology Language" (TONTO).

## ğŸ“– Sobre o Projeto

**TONTO** (Textual Ontology Language) Ã© uma linguagem textual para a especificaÃ§Ã£o de ontologias computacionais. Este projeto implementa a primeira fase de um compilador para a linguagem, o **analisador lÃ©xico**, responsÃ¡vel por ler o cÃ³digo-fonte `.tonto` e convertÃª-lo em uma sequÃªncia de tokens (as menores unidades lÃ³gicas da linguagem).

O analisador foi construÃ­do em Python utilizando a biblioteca [PLY (Python Lex-Yacc)](http://www.dabeaz.com/ply/).

## âœ¨ Funcionalidades

*   **Reconhecimento Completo**: Identifica todos os estereÃ³tipos, palavras-chave e sÃ­mbolos especiais da linguagem TONTO.

*   **Identificadores Complexos**: Classifica corretamente os diferentes tipos de identificadores:
    *   `CLASS_NAME` (Ex: `Car`, `Criterion_A2i`)
    *   `INSTANCE_NAME` (Ex: `Planeta2`)
    *   `RELATION_NAME` (Ex: `involvesOwner`)
    *   `NEW_DATATYPE` (Ex: `CPFDataType`)

*   **Literais**: Analisa e extrai valores de `STRING`, `DATE_LITERAL`, `TIME_LITERAL` e `DATETIME_LITERAL`.

*   **Interface Interativa**: Um menu de linha de comando (CLI) amigÃ¡vel para testar exemplos internos ou analisar arquivos `.tonto` externos.

*   **Dupla VisualizaÃ§Ã£o de SaÃ­da**:
    *   **VisÃ£o AnalÃ­tica**: Uma lista detalhada de cada token encontrado, seu lexema (valor) e a linha.
    *   **Tabela de SÃ­ntese**: Um resumo quantitativo com a contagem de cada tipo de token ao final da anÃ¡lise.

*   **RelatÃ³rio de Erros**: Captura caracteres ilegais e informa a linha onde o erro lÃ©xico ocorreu.

## ğŸ› ï¸ Tecnologias Utilizadas

*   Python 3.x
*   [PLY (Python Lex-Yacc)](http://www.dabeaz.com/ply/)

## ğŸ“ Estrutura de Pastas

Para que o programa funcione corretamente, os arquivos devem estar organizados da seguinte forma:

```
seu-projeto/
â”œâ”€â”€ lexer/
â”‚   â”œâ”€â”€ __init__.py          (Arquivo vazio, necessÃ¡rio para o Python)
â”‚   â”œâ”€â”€ lexer.py             (A lÃ³gica do analisador lÃ©xico)
â”‚   â””â”€â”€ tokens.py            (DefiniÃ§Ã£o dos tokens e palavras reservadas)
â”œâ”€â”€ main.py                  (O script principal para executar o programa)
â”œâ”€â”€ Trabalho_de_Anlise_...pdf (O PDF do trabalho)
â””â”€â”€ README.md                (Este arquivo)
```

> **Importante**: A pasta `lexer` deve conter um arquivo chamado `__init__.py` (pode estar vazio) para que o Python a reconheÃ§a como um pacote.

## ğŸš€ Como Rodar

O projeto depende de uma biblioteca externa, a PLY. Siga os passos abaixo para instalar e executar.

### 1. Requisitos

*   Python 3 instalado.

### 2. InstalaÃ§Ã£o da DependÃªncia

Abra seu terminal ou prompt de comando e instale a biblioteca `ply`:

```bash
pip install ply
```

### 3. ExecuÃ§Ã£o

Com a dependÃªncia instalada, basta rodar o arquivo `main.py` a partir da pasta raiz do projeto:

```bash
python main.py
```

Um menu interativo aparecerÃ¡ no seu terminal. VocÃª pode escolher um dos exemplos internos (1-4) ou a opÃ§Ã£o 5 para fornecer o caminho de um arquivo `.tonto` local para anÃ¡lise.

## ğŸ“‹ Exemplo de SaÃ­da

Ao selecionar uma opÃ§Ã£o no menu (como o Exemplo 2), a saÃ­da serÃ¡ parecida com esta:

```
==================================================
  SELECIONE O TESTE DE ANÃLISE LÃ‰XICA
==================================================
 1. CarOwnershipExample
 2. CarRentalExample
 3. FoodAllergyExample
 4. TDAHExample
 5. Testar Arquivo Externo (.tonto)
 Q. Sair
--------------------------------------------------
Digite o nÃºmero do teste (ou Q para sair): 2

##################################################
         Executando: CarRentalExample
##################################################

=== CÃ“DIGO FONTE ANALISADO ===
// Exemplo 2: Car Rental
package CarRental

kind Person
...
---------------------------------

=== VISÃƒO ANALÃTICA (LISTA DE TOKENS) ===
  [Tipo: PACKAGE              Lexema: 'package' Linha: 3]
  [Tipo: CLASS_NAME           Lexema: 'CarRental' Linha: 3]
  [Tipo: KIND                 Lexema: 'kind' Linha: 5]
  [Tipo: CLASS_NAME           Lexema: 'Person' Linha: 5]
  [Tipo: ROLE                 Lexema: 'role' Linha: 7]
  [Tipo: CLASS_NAME           Lexema: 'Employee' Linha: 7]
  [Tipo: SPECIALIZES          Lexema: 'specializes' Linha: 7]
  [Tipo: CLASS_NAME           Lexema: 'Person' Linha: 7]
  ...
  (e assim por diante)
  ...

==================================================
  === TABELA DE SÃNTESE (CONTAGEM DE TOKENS) ===
==================================================
  ADULT                      : 2
  AGEPHASE                   : 1
  ARROW_LR                   : 1
  AT                         : 3
  AVAILABLECAR               : 1
  CAR                        : 1
  CHARACTERIZATION           : 1
  CHILD                      : 2
  CLASS_NAME                 : 17
  COMMA                      : 2
  COMPLETE                   : 2
  CORPORATECUSTOMER          : 1
  CUSTOMER                   : 2
  DECEASEDPESON              : 2
  DISJOINT                   : 2
  EMPLOYEE                   : 2
  GENERAL                    : 2
  GENSET                     : 2
  KIND                       : 3
  LBRACE                     : 3
  LBRACKET                   : 3
  LIFESTATUS                 : 1
  LIVINGPERSON               : 5
  MEDIATION                  : 3
  ORGANIZATION               : 1
  PACKAGE                    : 1
  PERSON                     : 4
  PERSONALCUSTOMER           : 1
  PHASE                      : 5
  RBRACE                     : 3
  RBRACKET                   : 3
  RELATION_NAME              : 4
  RENTALCAR                  : 2
  RESPONSIBLEEMPLOYEE        : 2
  ROLE                       : 4
  ROLEMIXIN                  : 1
  SPECIFICS                  : 2
  SPECIALIZES                : 7
  TEENAGER                   : 2
  UNDERMAINTENANCECAR        : 1
```


---

## ğŸ—ï¸ Fase 2 â€” AnÃ¡lise SintÃ¡tica (Parser)

A segunda fase do projeto implementa o **Analisador SintÃ¡tico**. Enquanto o Lexer identifica as palavras, o Parser valida a gramÃ¡tica e constrÃ³i o sentido estrutural do cÃ³digo, gerando uma **Ãrvore SintÃ¡tica Abstrata (AST)**.

Esta etapa foi projetada para lidar com a alta flexibilidade da linguagem TONTO, suportando definiÃ§Ãµes aninhadas, cardinalidades opcionais e diferentes estilos de declaraÃ§Ã£o.

### ğŸš€ Destaques da ImplementaÃ§Ã£o SintÃ¡tica

1.  **Suporte a RelaÃ§Ãµes Complexas**:
    * **RelaÃ§Ãµes Inline**: Captura relaÃ§Ãµes definidas em uma Ãºnica linha (ex: `@material relation A [1] -- faz -- [1] B`).
    * **Relatores (Bloco)**: Processa entidades relacionais complexas (`relator`) que contÃªm mÃºltiplas mediaÃ§Ãµes internas.
    * **Tratamento de Cardinalidades**: Reconhece cardinalidades opcionais tanto na origem quanto no destino (`[1..*]`), alÃ©m de identificar corretamente a direÃ§Ã£o das setas (`<>--`, `--<>`, `--`).

2.  **Generalization Sets (Gensets)**:
    * Reconhece as duas formas de declaraÃ§Ã£o: a forma linear (`where ...`) e a forma em bloco (`{ general ... specifics ... }`).
    * Suporte completo a modificadores (`disjoint`, `complete`) e categorizadores (`categorizer`).

3.  **VisualizaÃ§Ã£o HierÃ¡rquica AmigÃ¡vel**:
    * Em vez de apenas exibir um JSON bruto, o sistema renderiza uma **Ãrvore Visual** no terminal.
    * Isso permite entender rapidamente a hierarquia de Pacotes, Classes, Atributos e como as RelaÃ§Ãµes conectam as entidades.

### ğŸ’» Exemplos de Entrada e SaÃ­da

#### Exemplo 1: Relatores e RelaÃ§Ãµes Inline (Caso "Pizzaria")

**CÃ³digo Fonte (`.tonto`):**
```tonto
import Pessoa
package Pizzaria

@material relation Cliente [1..*] -- solicita -- [1..*] Pizza

relator Atendimento {
    @mediation [1..*] -- [1..*] Atendente
    @mediation [1..*] -- [1..*] Cliente
    @mediation [1..*] -- [1..*] Item
}
````

**SaÃ­da Visual do Parser:**

```text
ğŸ“¥ IMPORTS:
   â€¢ Pessoa

   â”‚
   â–¼
ğŸ“¦ PACOTE: Pizzaria
   â”‚
   â”œâ”€â”€ âš¡ RELAÃ‡ÃƒO INLINE: solicita
   â”‚   â”œâ”€â”€ EstereÃ³tipo: <<material>>
   â”‚   â””â”€â”€ Cliente [1..*] -- solicita -- [1..*] Pizza
   â”‚
   â””â”€â”€ ğŸ”— RELAÃ‡ÃƒO EXTERNA: Atendimento
       â”œâ”€â”€ Tipo: <<relator>>
       â”œâ”€â”€ Conecta: <<mediation>> [1..*] -- [1..*] â Atendente
       â”œâ”€â”€ Conecta: <<mediation>> [1..*] -- [1..*] â Cliente
       â””â”€â”€ Conecta: <<mediation>> [1..*] -- [1..*] â Item
```

#### Exemplo 2: Classes e Gensets

**CÃ³digo Fonte (`.tonto`):**

```tonto
package Genealogy

kind Person
phase Child specializes Person
phase Adult specializes Person

genset LifeStages {
    general Person
    specifics Child, Adult
}
```

**SaÃ­da Visual do Parser:**

```text
ğŸ“¦ PACOTE: Genealogy
   â”‚
   â”œâ”€â”€ ğŸ“„ CLASSE: Person
   â”‚   â”œâ”€â”€ EstereÃ³tipo: <<kind>>
   â”‚   â””â”€â”€ (Sem atributos ou relaÃ§Ãµes internas)
   â”œâ”€â”€ ğŸ“„ CLASSE: Child
   â”‚   â”œâ”€â”€ EstereÃ³tipo: <<phase>> â¡ï¸ Specializes: Person
   â”‚   â””â”€â”€ (Sem atributos ou relaÃ§Ãµes internas)
   â”œâ”€â”€ ğŸ“„ CLASSE: Adult
   â”‚   â”œâ”€â”€ EstereÃ³tipo: <<phase>> â¡ï¸ Specializes: Person
   â”‚   â””â”€â”€ (Sem atributos ou relaÃ§Ãµes internas)
   â””â”€â”€ ğŸ”± GENSET: LifeStages
       â”œâ”€â”€ Propriedades: Normal
       â”œâ”€â”€ Geral: Person
       â””â”€â”€ EspecÃ­ficos: Child, Adult
```
## ğŸ” Fase 3 â€” AnÃ¡lise SemÃ¢ntica (Em Breve)

A prÃ³xima etapa consistirÃ¡ na validaÃ§Ã£o das regras lÃ³gicas da ontologia, como:

  * VerificaÃ§Ã£o de tipos incompatÃ­veis.
  * ConsistÃªncia das cardinalidades e naturezas ontolÃ³gicas.
  * Checagem de identificadores nÃ£o declarados.

<!-- end list -->

```
```
